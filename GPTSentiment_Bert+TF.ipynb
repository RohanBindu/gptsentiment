{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rU1VMPuJA9gU",
        "outputId": "de67611a-eed6-4259-b3db-8856e32b7657"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (4.31.0)\n",
            "Requirement already satisfied: filelock in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from transformers) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: nlpaug in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (1.1.11)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from nlpaug) (1.24.3)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from nlpaug) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.22.0 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from nlpaug) (2.31.0)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from nlpaug) (4.7.1)\n",
            "Requirement already satisfied: filelock in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from gdown>=4.0.0->nlpaug) (3.12.2)\n",
            "Requirement already satisfied: six in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from gdown>=4.0.0->nlpaug) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from gdown>=4.0.0->nlpaug) (4.65.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from gdown>=4.0.0->nlpaug) (4.12.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from pandas>=1.2.0->nlpaug) (2023.3)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from pandas>=1.2.0->nlpaug) (2023.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from requests>=2.22.0->nlpaug) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from requests>=2.22.0->nlpaug) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from requests>=2.22.0->nlpaug) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from requests>=2.22.0->nlpaug) (2023.7.22)\n",
            "Requirement already satisfied: soupsieve>1.2 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.3.2.post1)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from requests>=2.22.0->nlpaug) (1.7.1)\n",
            "Collecting nltk\n",
            "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
            "Requirement already satisfied: click in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from nltk) (8.1.6)\n",
            "Requirement already satisfied: joblib in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from nltk) (1.3.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from nltk) (4.65.0)\n",
            "Installing collected packages: nltk\n",
            "Successfully installed nltk-3.8.1\n",
            "Requirement already satisfied: torch in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (2.0.1)\n",
            "Requirement already satisfied: filelock in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: pandas in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from pandas) (1.24.3)\n",
            "Requirement already satisfied: six>=1.5 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install nlpaug\n",
        "!pip install nltk\n",
        "!pip install torch\n",
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from pandas) (1.24.3)\n",
            "Requirement already satisfied: six>=1.5 in /Users/romoney0/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dbyoh6XPBhWG"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import collections\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from transformers import BertTokenizer\n",
        "from sklearn.utils import shuffle\n",
        "from transformers import BertForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wnK8_ygaBlQz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'neutral': 0, 'good': 1, 'bad': 2}\n",
            "                                              tweets   labels\n",
            "0  ChatGPT: Optimizing Language Models for Dialog...  neutral\n",
            "1  Try talking with ChatGPT, our new AI system wh...     good\n",
            "2  ChatGPT: Optimizing Language Models for Dialog...  neutral\n",
            "3  THRILLED to share that ChatGPT, our new model ...     good\n",
            "4  As of 2 minutes ago, @OpenAI released their ne...      bad\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"gptsentiment.csv\")\n",
        "df = df[[\"tweets\", \"labels\"]].dropna().reset_index(drop=True)\n",
        "df = df[:5000]\n",
        "labelset = df.labels.unique()\n",
        "label_map = {labelset[i]:i for i in range(len(labelset))}\n",
        "print(label_map)\n",
        "reverse_map = {i:labelset[i] for i in range(len(labelset))}\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Hm_oUcPxSeyK"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "labels\n",
              "bad        2343\n",
              "good       1355\n",
              "neutral    1302\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['labels'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_TlKKTDRS-Wo"
      },
      "outputs": [],
      "source": [
        "df['labels'] = df['labels'].map(label_map)\n",
        "df.head()\n",
        "oglist = list(df.labels.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "x_dnCnmCTZtG"
      },
      "outputs": [],
      "source": [
        "import nlpaug.augmenter.word.context_word_embs as aug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sJP6WY5UTl0d"
      },
      "outputs": [],
      "source": [
        "augmenter = aug.ContextualWordEmbsAug(model_path='bert-base-uncased', action=\"insert\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fgJTZF_VTnBB"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a9759659f04046349980ac1210d53422",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d154db67a1104dfc9ae1aa65cb72ff72",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c91de1f925d44a21857d6432ca863832",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jKLMoskOTqgo"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-26 11:34:03.612909: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
            "2023-09-26 11:34:03.612946: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
            "2023-09-26 11:34:03.612960: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
            "2023-09-26 11:34:03.613028: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2023-09-26 11:34:03.613065: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
          ]
        }
      ],
      "source": [
        "token = tokenizer.encode_plus(\n",
        "    df['tweets'].iloc[0],\n",
        "    max_length=256,\n",
        "    truncation=True,\n",
        "    padding='max_length',\n",
        "    add_special_tokens=True,\n",
        "    return_tensors='tf'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PKkEZ9ZXTyfF"
      },
      "outputs": [],
      "source": [
        "X_input_ids = np.zeros((len(df), 256))\n",
        "X_attn_masks = np.zeros((len(df), 256))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "LuhGMboNTzDw"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5000, 256)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_input_ids.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "oA0_6YQjT1_c"
      },
      "outputs": [],
      "source": [
        "def generate_training_data(df, ids, masks, tokenizer):\n",
        "    for i, text in tqdm(enumerate(df['tweets'])):\n",
        "        tokenized_text = tokenizer.encode_plus(\n",
        "            text,\n",
        "            max_length=256,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            add_special_tokens=True,\n",
        "            return_tensors='tf'\n",
        "        )\n",
        "        ids[i, :] = tokenized_text.input_ids\n",
        "        masks[i, :] = tokenized_text.attention_mask\n",
        "    return ids, masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "YLt06Y6rT5Qq"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "91d937a16daa4075931fecf92f11fa40",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        " X_input_ids, X_attn_masks = generate_training_data(df, X_input_ids, X_attn_masks, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "8-V-yu1QT7Kw"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5000, 3)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels = np.zeros((len(df), len(df.labels.unique())))\n",
        "labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ebHdWZoOT_6K"
      },
      "outputs": [],
      "source": [
        "labels[np.arange(len(df)), df['labels'].values] = 1 # one-hot encoded target tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "OYbkCbOTUC0j"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.]])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "EWZbItQGUERD"
      },
      "outputs": [],
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((X_input_ids, X_attn_masks, labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "A5Ub96zdUF53"
      },
      "outputs": [],
      "source": [
        "def LabelDatasetMapFunction(input_ids, attn_masks, labels):\n",
        "    return {\n",
        "        'input_ids': input_ids,\n",
        "        'attention_mask': attn_masks\n",
        "    }, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "BAx-TITQUJfJ"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.map(LabelDatasetMapFunction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "MKOhpCqfULxH"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.shuffle(10000).batch(3, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "GM__ZWpGUNhd"
      },
      "outputs": [],
      "source": [
        "p = 0.8\n",
        "train_size = int((len(df)//3)*p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "9wsRbanyUf9G"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1332"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "VzsO53wgUiIW"
      },
      "outputs": [],
      "source": [
        "train_dataset = dataset.take(train_size)\n",
        "val_dataset = dataset.skip(train_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "mffp16FsUi4z"
      },
      "outputs": [],
      "source": [
        "from transformers import TFBertModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "eMIuaAsoUkJi"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "36e643bd65c94b65b56fe7a0ea82d8c2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "model = TFBertModel.from_pretrained('bert-base-cased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "YEWIlfjZUk-M"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)      [(None, 256)]                0         []                            \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer  [(None, 256)]                0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " bert (TFBertMainLayer)      TFBaseModelOutputWithPooli   1083102   ['input_ids[0][0]',           \n",
            "                             ngAndCrossAttentions(last_   72         'attention_mask[0][0]']      \n",
            "                             hidden_state=(None, 256, 7                                           \n",
            "                             68),                                                                 \n",
            "                              pooler_output=(None, 768)                                           \n",
            "                             , past_key_values=None, hi                                           \n",
            "                             dden_states=None, attentio                                           \n",
            "                             ns=None, cross_attentions=                                           \n",
            "                             None)                                                                \n",
            "                                                                                                  \n",
            " intermediate_layer (Dense)  (None, 512)                  393728    ['bert[0][1]']                \n",
            "                                                                                                  \n",
            " output_layer (Dense)        (None, 3)                    1539      ['intermediate_layer[0][0]']  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 108705539 (414.68 MB)\n",
            "Trainable params: 108705539 (414.68 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "input_ids = tf.keras.layers.Input(shape=(256,), name='input_ids', dtype='int32')\n",
        "attn_masks = tf.keras.layers.Input(shape=(256,), name='attention_mask', dtype='int32')\n",
        "\n",
        "bert_embds = model.bert(input_ids, attention_mask=attn_masks)[1] # 0 -> activation layer (3D), 1 -> pooled output layer (2D)\n",
        "intermediate_layer = tf.keras.layers.Dense(512, activation='relu', name='intermediate_layer')(bert_embds)\n",
        "output_layer = tf.keras.layers.Dense(len(df.labels.unique()), activation='softmax', name='output_layer')(intermediate_layer) # softmax -> calcs probs of classes\n",
        "\n",
        "tickets_model = tf.keras.Model(inputs=[input_ids, attn_masks], outputs=output_layer)\n",
        "tickets_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "D1h50iXLUoFk"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.optimizers.adam.Adam at 0x30b2dfdf0>"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "optim = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "loss_func = tf.keras.losses.CategoricalCrossentropy()\n",
        "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
        "optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "alEc_iNeUqDN"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.01,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.9)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "8_mF6vSOUr-_"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
          ]
        }
      ],
      "source": [
        "tickets_model.compile(optimizer=optim, loss=loss_func, metrics=[acc])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "3W2cvA55UttZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-26 11:34:57.776387: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1332/1332 [==============================] - ETA: 0s - loss: 0.8568 - accuracy: 0.6104"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-26 11:40:54.194428: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1332/1332 [==============================] - 387s 277ms/step - loss: 0.8568 - accuracy: 0.6104 - val_loss: 0.6524 - val_accuracy: 0.7295\n",
            "Epoch 2/5\n",
            "1332/1332 [==============================] - 359s 270ms/step - loss: 0.5993 - accuracy: 0.7568 - val_loss: 0.4539 - val_accuracy: 0.8323\n",
            "Epoch 3/5\n",
            "1332/1332 [==============================] - 358s 268ms/step - loss: 0.4486 - accuracy: 0.8178 - val_loss: 0.3059 - val_accuracy: 0.8812\n",
            "Epoch 4/5\n",
            "1332/1332 [==============================] - 461s 346ms/step - loss: 0.3320 - accuracy: 0.8749 - val_loss: 0.2348 - val_accuracy: 0.9162\n",
            "Epoch 5/5\n",
            "1332/1332 [==============================] - 409s 307ms/step - loss: 0.2356 - accuracy: 0.9154 - val_loss: 0.1747 - val_accuracy: 0.9471\n"
          ]
        }
      ],
      "source": [
        "hist = tickets_model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBIPqf0dJjjF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "a_NFl5ozUuqB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: tickets_model/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: tickets_model/assets\n"
          ]
        }
      ],
      "source": [
        "tickets_model.save('tickets_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "YEDypw1JWD1X"
      },
      "outputs": [],
      "source": [
        "tickets_model = tf.keras.models.load_model('tickets_model')\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "\n",
        "def prepare_data(input_text, tokenizer):\n",
        "    token = tokenizer.encode_plus(\n",
        "        input_text,\n",
        "        max_length=256,\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        add_special_tokens=True,\n",
        "        return_tensors='tf'\n",
        "    )\n",
        "    return {\n",
        "        'input_ids': tf.cast(token.input_ids, tf.float64),\n",
        "        'attention_mask': tf.cast(token.attention_mask, tf.float64)\n",
        "    }\n",
        "\n",
        "def make_prediction(model, processed_data, classes=oglist):\n",
        "    probs = model.predict(processed_data)[0]\n",
        "    return classes[np.argmax(probs)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "zA_M9gcxWFmL"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-26 12:09:36.905797: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 7s 7s/step\n",
            "Predicted Service: bad\n"
          ]
        }
      ],
      "source": [
        "input_text = input('Enter gpt sentiment analysis here: ')\n",
        "processed_data = prepare_data(input_text, tokenizer)\n",
        "result = make_prediction(tickets_model, processed_data=processed_data)\n",
        "print(f\"Predicted Service: {reverse_map[result]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "7WU7Nb46WWJr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1, 2]\n"
          ]
        }
      ],
      "source": [
        "print(oglist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
